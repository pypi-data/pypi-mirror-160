---

title: tqdm


keywords: fastai
sidebar: home_sidebar

summary: "Utilities to use tqdm with joblib"
description: "Utilities to use tqdm with joblib"
nb_path: "01_tqdm.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 01_tqdm.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="ProgressParallel" class="doc_header"><code>class</code> <code>ProgressParallel</code><a href="https://github.com/gngdb/llamass/tree/master/llamass/tqdm.py#L9" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>ProgressParallel</code>(<strong><code>n_jobs</code></strong>=<em><code>None</code></em>, <strong><code>backend</code></strong>=<em><code>None</code></em>, <strong><code>verbose</code></strong>=<em><code>0</code></em>, <strong><code>timeout</code></strong>=<em><code>None</code></em>, <strong><code>pre_dispatch</code></strong>=<em>`'2 </em> n_jobs'<code>*, **</code>batch_size<code>**=*</code>'auto'<code>*, **</code>temp_folder<code>**=*</code>None<code>*, **</code>max_nbytes<code>**=*</code>'1M'<code>*, **</code>mmap_mode<code>**=*</code>'r'<code>*, **</code>prefer<code>**=*</code>None<code>*, **</code>require<code>**=*</code>None<code>*) ::</code>Parallel`</p>
</blockquote>
<p>Helper class for readable parallel mapping.</p>
<p>Read more in the :ref:<code>User Guide &lt;parallel&gt;</code>.</p>
<h2 id="Parameters">Parameters<a class="anchor-link" href="#Parameters"> </a></h2><p>n_jobs: int, default: None
    The maximum number of concurrently running jobs, such as the number
    of Python worker processes when backend="multiprocessing"
    or the size of the thread-pool when backend="threading".
    If -1 all CPUs are used. If 1 is given, no parallel computing code
    is used at all, which is useful for debugging. For n_jobs below -1,
    (n_cpus + 1 + n_jobs) are used. Thus for n_jobs = -2, all
    CPUs but one are used.
    None is a marker for 'unset' that will be interpreted as n_jobs=1
    (sequential execution) unless the call is performed under a
    parallel_backend context manager that sets another value for
    n_jobs.
backend: str, ParallelBackendBase instance or None, default: 'loky'
    Specify the parallelization backend implementation.
    Supported backends are:</p>

<pre><code>- "loky" used by default, can induce some
  communication and memory overhead when exchanging input and
  output data with the worker Python processes.
- "multiprocessing" previous process-based backend based on
  `multiprocessing.Pool`. Less robust than `loky`.
- "threading" is a very low-overhead backend but it suffers
  from the Python Global Interpreter Lock if the called function
  relies a lot on Python objects. "threading" is mostly useful
  when the execution bottleneck is a compiled extension that
  explicitly releases the GIL (for instance a Cython loop wrapped
  in a "with nogil" block or an expensive call to a library such
  as NumPy).
- finally, you can register backends by calling
  register_parallel_backend. This will allow you to implement
  a backend of your liking.

It is not recommended to hard-code the backend name in a call to
Parallel in a library. Instead it is recommended to set soft hints
(prefer) or hard constraints (require) so as to make it possible
for library users to change the backend from the outside using the
parallel_backend context manager.
</code></pre>
<p>prefer: str in {'processes', 'threads'} or None, default: None
    Soft hint to choose the default backend if no specific backend
    was selected with the parallel_backend context manager. The
    default process-based backend is 'loky' and the default
    thread-based backend is 'threading'. Ignored if the <code>backend</code>
    parameter is specified.
require: 'sharedmem' or None, default None
    Hard constraint to select the backend. If set to 'sharedmem',
    the selected backend will be single-host and thread-based even
    if the user asked for a non-thread based backend with
    parallel_backend.
verbose: int, optional
    The verbosity level: if non zero, progress messages are
    printed. Above 50, the output is sent to stdout.
    The frequency of the messages increases with the verbosity level.
    If it more than 10, all iterations are reported.
timeout: float, optional
    Timeout limit for each task to complete.  If any task takes longer
    a TimeOutError will be raised. Only applied when n_jobs != 1
pre_dispatch: {'all', integer, or expression, as in '3<em>n_jobs'}
    The number of batches (of tasks) to be pre-dispatched.
    Default is '2</em>n_jobs'. When batch_size="auto" this is reasonable
    default and the workers should never starve.
batch_size: int or 'auto', default: 'auto'
    The number of atomic tasks to dispatch at once to each
    worker. When individual evaluations are very fast, dispatching
    calls to workers can be slower than sequential computation because
    of the overhead. Batching fast computations together can mitigate
    this.
    The <code>'auto'</code> strategy keeps track of the time it takes for a batch
    to complete, and dynamically adjusts the batch size to keep the time
    on the order of half a second, using a heuristic. The initial batch
    size is 1.
    <code>batch_size="auto"</code> with <code>backend="threading"</code> will dispatch
    batches of a single task at a time as the threading backend has
    very little overhead and using larger batch size has not proved to
    bring any gain in that case.
temp_folder: str, optional
    Folder to be used by the pool for memmapping large arrays
    for sharing memory with worker processes. If None, this will try in
    order:</p>

<pre><code>- a folder pointed by the JOBLIB_TEMP_FOLDER environment
  variable,
- /dev/shm if the folder exists and is writable: this is a
  RAM disk filesystem available by default on modern Linux
  distributions,
- the default system temporary folder that can be
  overridden with TMP, TMPDIR or TEMP environment
  variables, typically /tmp under Unix operating systems.

Only active when backend="loky" or "multiprocessing".
</code></pre>
<p>max_nbytes int, str, or None, optional, 1M by default
    Threshold on the size of arrays passed to the workers that
    triggers automated memory mapping in temp_folder. Can be an int
    in Bytes, or a human-readable string, e.g., '1M' for 1 megabyte.
    Use None to disable memmapping of large arrays.
    Only active when backend="loky" or "multiprocessing".
mmap_mode: {None, 'r+', 'r', 'w+', 'c'}
    Memmapping mode for numpy arrays passed to workers.
    See 'max_nbytes' parameter documentation for more details.</p>
<h2 id="Notes">Notes<a class="anchor-link" href="#Notes"> </a></h2><p>This object uses workers to compute in parallel the application of a
function to many different arguments. The main functionality it brings
in addition to using the raw multiprocessing or concurrent.futures API
are (see examples for details):</p>
<ul>
<li><p>More readable code, in particular since it avoids
constructing list of arguments.</p>
</li>
<li><p>Easier debugging:</p>
<ul>
<li>informative tracebacks even when the error happens on
the client side</li>
<li>using 'n_jobs=1' enables to turn off parallel computing
for debugging without changing the codepath</li>
<li>early capture of pickling errors</li>
</ul>
</li>
<li><p>An optional progress meter.</p>
</li>
<li><p>Interruption of multiprocesses jobs with 'Ctrl-C'</p>
</li>
<li><p>Flexible pickling control for the communication to and from
the worker processes.</p>
</li>
<li><p>Ability to use shared memory efficiently with worker
processes for large numpy-based datastructures.</p>
</li>
</ul>
<h2 id="Examples">Examples<a class="anchor-link" href="#Examples"> </a></h2><p>A simple example:</p>
<blockquote><blockquote><blockquote><p>from math import sqrt
from joblib import Parallel, delayed
Parallel(n_jobs=1)(delayed(sqrt)(i**2) for i in range(10))
[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]</p>
</blockquote>
</blockquote>
</blockquote>
<p>Reshaping the output when the function has several return
values:</p>
<blockquote><blockquote><blockquote><p>from math import modf
from joblib import Parallel, delayed
r = Parallel(n_jobs=1)(delayed(modf)(i/2.) for i in range(10))
res, i = zip(*r)
res
(0.0, 0.5, 0.0, 0.5, 0.0, 0.5, 0.0, 0.5, 0.0, 0.5)
i
(0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 4.0)</p>
</blockquote>
</blockquote>
</blockquote>
<p>The progress meter: the higher the value of <code>verbose</code>, the more
messages:</p>
<blockquote><blockquote><blockquote><p>from time import sleep
from joblib import Parallel, delayed
r = Parallel(n<em>jobs=2, verbose=10)(delayed(sleep)(.2) for </em> in range(10)) #doctest: +SKIP
[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:    0.6s
[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:    0.8s
[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:    1.4s finished</p>
</blockquote>
</blockquote>
</blockquote>
<p>Traceback example, note how the line of the error is indicated
as well as the values of the parameter passed to the function that
triggered the exception, even though the traceback happens in the
child process:</p>
<blockquote><blockquote><blockquote><p>from heapq import nlargest
from joblib import Parallel, delayed
Parallel(n_jobs=2)(delayed(nlargest)(2, n) for n in (range(4), 'abcde', 3)) #doctest: +SKIP</p>
<h1 id="...">...<a class="anchor-link" href="#..."> </a></h1><hr>
<h2 id="Sub-process-traceback:">Sub-process traceback:<a class="anchor-link" href="#Sub-process-traceback:"> </a></h2><p>TypeError                                          Mon Nov 12 11:37:46 2012
PID: 12934                                    Python 2.7.3: /usr/bin/python
...........................................................................
/usr/lib/python2.7/heapq.pyc in nlargest(n=2, iterable=3, key=None)
    419         if n &gt;= size:
    420             return sorted(iterable, key=key, reverse=True)[:n]
    421
    422     # When key is none, use simpler decoration
    423     if key is None:
--&gt; 424         it = izip(iterable, count(0,-1))                    # decorate
    425         result = _nlargest(n, it)
    426         return map(itemgetter(0), result)                   # undecorate
    427
    428     # General case, slowest method
 TypeError: izip argument #1 must support iteration</p>
<hr>
</blockquote>
</blockquote>
</blockquote>
<p>Using pre_dispatch in a producer/consumer situation, where the
data is generated on the fly. Note how the producer is first
called 3 times before the parallel loop is initiated, and then
called to generate new data on the fly:</p>
<blockquote><blockquote><blockquote><p>from math import sqrt
from joblib import Parallel, delayed
def producer():
...     for i in range(6):
...         print('Produced %s' % i)
...         yield i
out = Parallel(n_jobs=2, verbose=100, pre_dispatch='1.5*n_jobs')(
...                delayed(sqrt)(i) for i in producer()) #doctest: +SKIP
Produced 0
Produced 1
Produced 2
[Parallel(n_jobs=2)]: Done 1 jobs     | elapsed:  0.0s
Produced 3
[Parallel(n_jobs=2)]: Done 2 jobs     | elapsed:  0.0s
Produced 4
[Parallel(n_jobs=2)]: Done 3 jobs     | elapsed:  0.0s
Produced 5
[Parallel(n_jobs=2)]: Done 4 jobs     | elapsed:  0.0s
[Parallel(n_jobs=2)]: Done 6 out of 6 | elapsed:  0.0s remaining: 0.0s
[Parallel(n_jobs=2)]: Done 6 out of 6 | elapsed:  0.0s finished</p>
</blockquote>
</blockquote>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">joblib</span>
<span class="kn">from</span> <span class="nn">tqdm.auto</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="k">class</span> <span class="nc">ProgressParallel</span><span class="p">(</span><span class="n">joblib</span><span class="o">.</span><span class="n">Parallel</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;total&quot;</span><span class="p">])</span> <span class="k">as</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pbar</span><span class="p">:</span>
            <span class="k">del</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;total&quot;</span><span class="p">]</span>
            <span class="k">return</span> <span class="n">joblib</span><span class="o">.</span><span class="n">Parallel</span><span class="o">.</span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">print_progress</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_pbar</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_completed_tasks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_pbar</span><span class="o">.</span><span class="n">refresh</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

</div>
 

