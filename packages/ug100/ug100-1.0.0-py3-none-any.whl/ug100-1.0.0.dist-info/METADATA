Metadata-Version: 2.1
Name: ug100
Version: 1.0.0
Summary: Dataset containing adversarial results for seven approximate attacks (+ MIP) on MNIST and CIFAR10.
Project-URL: Homepage, https://github.com/samuelemarro/ug100
Project-URL: Bug Tracker, https://github.com/samuelemarro/ug100
Author-email: Samuele Marro <marrosamuele@gmail.com>
License: MIT License
        
        Copyright (c) 2022 Samuele Marro
        
        Permission is hereby granted, free of charge, to any person obtaining a copy
        of this software and associated documentation files (the "Software"), to deal
        in the Software without restriction, including without limitation the rights
        to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
        copies of the Software, and to permit persons to whom the Software is
        furnished to do so, subject to the following conditions:
        
        The above copyright notice and this permission notice shall be included in all
        copies or substantial portions of the Software.
        
        THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
        IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
        FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
        AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
        LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
        OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
        SOFTWARE.
Keywords: adversarial,attack,cifar10,dataset,mip,mixed-integer programming,mnist
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Requires-Python: >=3.7
Requires-Dist: torch>=1.7.1
Requires-Dist: tqdm>=4.64.0
Description-Content-Type: text/markdown

# UG100

A dataset containing adversarial results for seven approximate attacks (+ MIP) on a subset of the MNIST and CIFAR10 test datasets. Specifically, it contains ~2.3k adversarial examples generated by the following attacks:
- Basic Iterative Method (`bim`)
- Brendel & Bethge Attack (`brendel`)
- Carlini & Wagner Attack (`carlini`)
- Deepfool (`deepfool`)
- Fast Gradient Sign Method (`fast_gradient`)
- Projected Gradient Descent (`pgd`)
- Uniform noise (`uniform`)
- MIPVerify (`mip`)

It also includes adversarial distances (for all attacks) and bounds (for MIP), as well as MIP convergence times.

Applications of this dataset include:

- Studying how, whenÂ and why adversarial attacks are close-to-optimal;
- Training classifiers that are robust to adversarial noise;
- Benchmarking new adversarial attacks.

The code used to generate UG100 can be found [here](https://github.com/samuelemarro/counter-attack).

# Installation

```
pip install ug100
```

# Implementation Notes

Since there aren't adversarial examples for every element of the test sets, we store the adversarials as an index-to-results dictionary.
For sequential access, use `IndexDataset`.

Additionally, we do not store the corresponding genuine examples for MNIST and CIFAR10. If you're using PyTorch, consider using [TorchVision's dataset library](https://pytorch.org/vision/stable/datasets.html).

# Citing this Dataset

Please cite this dataset as:
```
Samuele Marro and Michele Lombardi. _Asymmetries in Adversarial Settings_. 2022.
```