Metadata-Version: 2.1
Name: ai-dataproc
Version: 0.1.0
Summary: 
Author: nuxion
Author-email: nuxion@gmail.com
Requires-Python: >=3.8,<3.11
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Provides-Extra: crawl
Provides-Extra: social
Provides-Extra: words
Requires-Dist: Unidecode (>=1.3.2,<2.0.0)
Requires-Dist: annoy (>=1.17.0,<2.0.0); extra == "words"
Requires-Dist: arrow (>=1.2.0,<2.0.0)
Requires-Dist: beautifulsoup4 (>=4.10.0,<5.0.0); extra == "crawl"
Requires-Dist: cityhash (>=0.2.3,<0.3.0)
Requires-Dist: cloudpickle (>=2.0.0,<3.0.0)
Requires-Dist: cytoolz (>=0.11.0,<0.12.0)
Requires-Dist: dateparser (>=1.1.0,<2.0.0)
Requires-Dist: emoji (>=1.5.0,<2.0.0); extra == "words"
Requires-Dist: extruct (>=0.13.0,<0.14.0); extra == "crawl"
Requires-Dist: feedparser (>=6.0.8,<7.0.0); extra == "crawl"
Requires-Dist: gensim (>=4.1.2,<5.0.0); extra == "words"
Requires-Dist: iso3166 (>=2.0.2,<3.0.0)
Requires-Dist: langcodes[data] (>=3.2.1,<4.0.0); extra == "words"
Requires-Dist: langdetect (>=1.0.9,<2.0.0)
Requires-Dist: lxml (>=4.6.3,<5.0.0); extra == "crawl"
Requires-Dist: newspaper3k (>=0.2.8,<0.3.0); extra == "crawl"
Requires-Dist: nltk (>=3.6.4,<4.0.0); extra == "words"
Requires-Dist: pandas (>=1.3.3,<2.0.0)
Requires-Dist: pyarrow (>=5.0.0,<6.0.0); extra == "crawl"
Requires-Dist: pymediawiki (>=0.7.1,<0.8.0); extra == "social"
Requires-Dist: pytextrank (>=3.2.1,<4.0.0); extra == "words"
Requires-Dist: python-Levenshtein (>=0.12.2,<0.13.0)
Requires-Dist: pytrends (>=4.7.3,<5.0.0); extra == "social"
Requires-Dist: pytz (>=2021.1,<2022.0)
Requires-Dist: reppy (>=0.4.14,<0.5.0); extra == "crawl"
Requires-Dist: scikit-learn (>=1.0,<2.0); extra == "words"
Requires-Dist: scikit-network (>=0.24.0,<0.25.0); extra == "words"
Requires-Dist: sentence-transformers (>=2.1.0,<3.0.0); extra == "words"
Requires-Dist: sentencepiece (>=0.1.96,<0.2.0); extra == "words"
Requires-Dist: spacy (>=3.1.3,<4.0.0); extra == "words"
Requires-Dist: tokenizers (>=0.10.3,<0.11.0); extra == "words"
Requires-Dist: transformers[torch] (>=4.13.0,<5.0.0); extra == "words"
Requires-Dist: tweepy (>=4.0.0,<5.0.0); extra == "social"
Requires-Dist: ujson (>=4.2.0,<5.0.0); extra == "crawl"
Requires-Dist: xxhash (>=2.0.2,<3.0.0)
