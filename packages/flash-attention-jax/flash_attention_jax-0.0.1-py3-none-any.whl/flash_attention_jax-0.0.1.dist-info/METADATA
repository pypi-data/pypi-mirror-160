Metadata-Version: 2.1
Name: flash-attention-jax
Version: 0.0.1
Summary: Flash Attention - in Jax
Home-page: https://github.com/lucidrains/flash-attention-jax
Author: Phil Wang
Author-email: lucidrains@gmail.com
License: MIT
Keywords: artificial intelligence,deep learning,transformers,attention mechanism,jax
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3.6
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: jax (>=0.2.20)

